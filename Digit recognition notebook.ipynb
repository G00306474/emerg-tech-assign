{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognition Notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KMora\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras as kr\n",
    "import sklearn.preprocessing as pre\n",
    "import tensorflow as tf\n",
    "import tkinter as tk # used to load img\n",
    "from tkinter import filedialog #for uploading image files\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with gzip.open('data/train-images-idx3-ubyte.gz', 'rb') as f: \n",
    "    file_content = f.read() \n",
    "\n",
    "with gzip.open('data/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    labels = f.read() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create our neural network. We are going to use 4 layers. The first thing we do is tell keras it will be sequential meaning multiply layers. We then use .add() to add each layer. \n",
    "The first layer we tell to have 1000 neurons and that the input dimension is 784(which we get from the rows by columns of our data set)\n",
    "We then tell it to have a dropout of 20% which means when each layer runs it will remove 20% of the neurons from the network. This is to limit the interdependency of each neuron on eachother.(If we leave this out accuracy will go up to 97% on test data but will have difficulty with user input)\n",
    "We do these two steps for each layer execpt the last to guarantee each neuron is trained at least once. \n",
    "We then create a output layer with 10 neurons which is for our ten possiable answers. \n",
    "Using optimiser adam as it was named the fastest and most consistent one [here](https://medium.com/octavian-ai/which-optimizer-and-learning-rate-should-i-use-for-deep-learning-5acb418f9b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.models import Model\n",
    "\n",
    "# Start a neural network, building it by layers.\n",
    "model = kr.models.Sequential()\n",
    "\n",
    "# Add a hidden layer with 1000 neurons and an input layer with 784.\n",
    "model.add(kr.layers.Dense(units=1000, activation='relu', input_dim=784, kernel_initializer=\"normal\"))\n",
    "model.add(Dropout(0.2)) #Dropout is a technique where randomly selected neurons are ignored during training. \n",
    "# They are “dropped-out” randomly. \n",
    "# This means that their contribution to the activation of downstream neurons is temporally removed on the \n",
    "# forward pass and any weight updates are not applied to the neuron on the backward pass.\n",
    "model.add(kr.layers.Dense(units=1000, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(kr.layers.Dense(units=1000, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(kr.layers.Dense(units=1000, activation='relu'))\n",
    "\n",
    "\n",
    "# Add a 10 neuron output layer.\n",
    "model.add(kr.layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "# Build the graph.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to import the training images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('data/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    train_img = f.read()\n",
    "\n",
    "with gzip.open('data/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    train_lbl = f.read()\n",
    "    \n",
    "train_img = ~np.array(list(train_img[16:])).reshape(60000, 28, 28).astype(np.uint8)\n",
    "train_lbl =  np.array(list(train_lbl[ 8:])).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = train_img.reshape(60000, 784)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 [0 0 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# For encoding categorical variables.\n",
    "encoder = pre.LabelBinarizer()\n",
    "encoder.fit(train_lbl)\n",
    "outputs = encoder.transform(train_lbl)\n",
    "\n",
    "print(train_lbl[0], outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks if there is a saved neural network. If there is it will use that if not it will create one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 121s 2ms/step - loss: 0.5480 - acc: 0.8220\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.3342 - acc: 0.8945\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 119s 2ms/step - loss: 0.2826 - acc: 0.9121\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 123s 2ms/step - loss: 0.2578 - acc: 0.9203 \n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 119s 2ms/step - loss: 0.2369 - acc: 0.9275\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 125s 2ms/step - loss: 0.2147 - acc: 0.9346 3s - loss: 0.215\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 122s 2ms/step - loss: 0.2051 - acc: 0.9371\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 121s 2ms/step - loss: 0.2072 - acc: 0.9365\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 119s 2ms/step - loss: 0.1988 - acc: 0.9392\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 121s 2ms/step - loss: 0.1804 - acc: 0.9449\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 122s 2ms/step - loss: 0.1762 - acc: 0.9456 5s -\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 123s 2ms/step - loss: 0.1716 - acc: 0.9477\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 122s 2ms/step - loss: 0.1651 - acc: 0.9489\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 124s 2ms/step - loss: 0.1611 - acc: 0.9501\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 122s 2ms/step - loss: 0.1592 - acc: 0.9511\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('savedModel.h5py'): \n",
    "    model = kr.models.load_model('savedModel.h5py')\n",
    "    print(\"Using precreated neuralNetwork. If you wish to create your own just rename or remove from folder file named savedModel.h5py \")\n",
    "else:\n",
    "    model.fit(inputs, outputs, epochs=15, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we save our model so we dont have to recreate it everytime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the current model\n",
    "kr.models.save_model(\n",
    "    model,\n",
    "    \"savedModel.h5py\",\n",
    "    overwrite=True,\n",
    "    include_optimizer=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('data/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    test_img = f.read()\n",
    "\n",
    "with gzip.open('data/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    test_lbl = f.read()\n",
    "    \n",
    "test_img = ~np.array(list(test_img[16:])).reshape(10000, 784).astype(np.uint8)\n",
    "test_lbl =  np.array(list(test_lbl[ 8:])).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will test our network against the test images and see how many it can correctly identify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST Test Images correctly identified:  9646 /10000\n"
     ]
    }
   ],
   "source": [
    "print(\"MNIST Test Images correctly identified: \",(encoder.inverse_transform(model.predict(test_img)) == test_lbl).sum(),\"/10000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will imput our own drawn image to testour neural network. When this is run a window will open that will let us select our file. \n",
    "When we select our file it will appear drawn in a window. \n",
    "Then once we close te window our network will try and determine what our drawn number is. You can use paint or gimp to draw your image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program has predicted :  [5]\n"
     ]
    }
   ],
   "source": [
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "#code source https://stackoverflow.com/questions/9319317/quick-and-easy-file-dialog-in-python\n",
    "\n",
    "file_path = filedialog.askopenfilename()# opens file select window\n",
    "img = image.load_img(path=file_path,color_mode = \"grayscale\",target_size=(28,28,1))\n",
    "#loads image into PIL format\n",
    "image1 = np.array(list(image.img_to_array(img))).reshape(1, 784).astype(np.uint8) / 255.0\n",
    "# shapes array \n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "test = model.predict(image1)\n",
    "print(\"program has predicted : \", test.argmax(axis=1))\n",
    "#code source https://towardsdatascience.com/basics-of-image-classification-with-keras-43779a299c8b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Optimizers](https://keras.io/optimizers/)   \n",
    "[Keras Model](https://keras.io/models/model/)   \n",
    "[Best Optimizers](https://medium.com/octavian-ai/which-optimizer-and-learning-rate-should-i-use-for-deep-learning-5acb418f9b2)   \n",
    "[Python Machine Learning Tutorial](https://www.python-course.eu/neural_network_mnist.php)   \n",
    "[How to classify MNIST digits with different neural network architectures](https://medium.com/tebs-lab/how-to-classify-mnist-digits-with-different-neural-network-architectures-39c75a0f03e3) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
